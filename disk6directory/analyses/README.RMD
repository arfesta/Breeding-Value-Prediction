# ANALYSES

## Step 1 - Data Prep

   Data prep includes everything from unpacking the original tar files recieved by the GSL up to estimating transcript               
      abundance with Salmon. Additionally, this step includes identification of the indicies used within both batches and creates an experimental info matrix containing all meta data from both batches.
      
   See the [raw reads README](../rawreads/README.md) for step by step processing of files.  

## Step 2 - Load Count Data
      
   Once counts have been estimated, the next step involves reading in the aligned technical, or biological replicate counts using the tximport package.
      
   Additionally, the phenotype and other sample meta-data is constructed for normalization.
   
   See the [load counts html file](http://htmlpreview.github.com/?https://github.com/arfesta/Breeding-Value-Prediction/blob/master/disk6directory/analyses/step2.loadcounts/load.counts.html) for complete markdown with outputs.

## Step 3 - Normalization

   The counts may be normalized using the sommer package and account for lane, index, and pedigree if 
    
   using the 576 techincal replicates. Output can be family or biological level log2 sample counts.

## Step 4 - Filtering

   Counts returned post-normalization are then applied to X different filters.
