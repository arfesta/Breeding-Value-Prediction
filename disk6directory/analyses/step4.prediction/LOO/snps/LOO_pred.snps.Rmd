---
title: 'Prediction of EW Volume BVâ€™s using LGEP: SNPs 012'
author: "Adam Festa"
date: "6/10/2018"
output: 
  html_document: 
    number_sections: yes
    theme: flatly
    toc: yes
    toc_depth: 5
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages(library(reshape2)); suppressPackageStartupMessages(library(parallel)); 
suppressPackageStartupMessages(library(OmicKriging));suppressPackageStartupMessages(library(glmnet)); 
suppressPackageStartupMessages(library(caret));suppressPackageStartupMessages(library(caretEnsemble));
suppressPackageStartupMessages(library(Metrics))
setwd("/mnt/media/disk6/ARF/shared")
```

## Load data

* First, load the --012 output produced during the SNP filtering.

* File loaded below has no missing snps, MAF > .05, and are of at least Q30.

* Additionally, the data frame contains rownames for bioloigcal samples and colnames as snp name/position

```{r load.snp.dat}
load("/mnt/bio.012.df.RData")
```

* Now load the phenotypes

```{r load phenos}
## Load phenotype data ####
#load("~/Documents/Grad_Projects/Breeding-Value-Prediction/disk6directory/resources/expt.dat.720.RData")
load("/mnt/Breeding-Value-Prediction/disk6directory/resources/expt.dat.720.RData")
expt.dat.720$animal_id <- as.character(expt.dat.720$animal_id)
expt.dat.720$fam_id <- as.character(expt.dat.720$fam_id)
expt.dat.720$batch <- as.character(expt.dat.720$batch)

# Create bio phenos from individuals with no missing Volume and who have unique, fam*animal*batch*vol combo
bio.phenos <- unique(expt.dat.720[which(!is.na(expt.dat.720$Volume) ==T),c("fam_id","animal_id","batch","Volume")])
```

* The bio phenos animal id and 012 matrix have the same style names but are not in the same order. Match 012 genos to phenotype data

```{r match}
# Index the snp data frame to only include individuals which have phenotypes
keep.index <-  which(rownames(bio.012.df) %in% bio.phenos$animal_id)

# Keep only those rows
bio.012.df <- bio.012.df[keep.index,]

bio.phenos <- bio.phenos[which(bio.phenos$animal_id %in% rownames(bio.012.df)),]
identical(bio.phenos$animal_id[match(rownames(bio.012.df),bio.phenos$animal_id)],rownames(bio.012.df))

bio.phenos <- bio.phenos[match(rownames(bio.012.df),bio.phenos$animal_id),]
rownames(bio.phenos) <- bio.phenos$animal_id
rm(keep.index)
```


## Generate family-level data

* Generate family phenos

```{r fam.phenos}
fam.phenos <- unique(bio.phenos[,c("fam_id","Volume")])
rownames(fam.phenos) <- fam.phenos$fam_id
u.fams <- unique(fam.phenos$fam_id)
```

* The family mean SNP matrix was generated once using the FULL bio 012 matrix and then saved. It's loaded here

```{r load.fam}
load("/mnt/fam.012.df.RData")
```

## Apply filters

* Apply caret filters including:

    * ANOVA scores: These are generated using phenotypes, so only the LGEP will be used to identify a subset to predict
    
    * BCV:  This may be generated without phenotypes, so the whole dataset will be used.
    
    * nearzerovar: This may also be used without phenotypes, so the whole dataset will be used.

### Generate anova scores

* Use caret package to generate anova scores with the LGEP 012 counts and phenos (i.e. `train.dat` & `train.phenos` objects)

```
# Using the biological replicates as the training set, we will subset a single family and then test anova scores across the remaining families.
family_anova_scores <- mclapply(1:56,function(each.fam){
 fam.rows <- which(bio.pheno.subset$fam_id %in% u.fams[each.fam])
 train.dat <- out.012.subset[-fam.rows,]
 train.p <- bio.pheno.subset$Volume[-fam.rows]
 apply(train.dat,2,function(each.snp) anovaScores(x = each.snp,y=train.p))
},mc.cores=32)

save(family_anova_scores,file="./LOO_fam_snp_anova.RData",compress=T)
```

```{r fam_anova}
load("/mnt/LOO_fam_snp_anova.RData")
# How many of anova scores are less than .05 (unadjusted)
hist(unlist(lapply(family_anova_scores,function(x) length(which(x < .05)))),main="# of SNPs which p < .05")
# How many of anova scores are less than .05 (adjusted)
hist(unlist(lapply(family_anova_scores,function(x) length(which(p.adjust(x) < .05)))),main="# of SNPs which adjusted p < .05")
```

* A range of 22,000 to 27,000 SNPs are < .05 with unadjusted p-values and approximately 75 to 180 SNPs are found with FDR adjusted p-values < .05 for each LOO CV.

### Filter BCV

* Here we will use the whole 012 data set to identify SNPs who have high BCV relative to all samples (BCV= sd/mean)

```{r bcv.stats}
# Estimate the variance, sd, mean, and bcv for each SNP
var.snps <- apply(bio.012.df,2,var)
sd.snps <- apply(bio.012.df,2,sd)
mean.snps <- apply(bio.012.df,2,mean)
bcv.snps <- sd.snps/mean.snps

# Take a look at the distribution of bcv values
hist(bcv.snps,main = "Histogram of BCV values for the whole 012 dataset",xlab="BCV value",ylab="# of SNPs")
length(which(bcv.snps > 3))
# Look at the histogram of variance using only those SNPs with bcv > 3
hist(var.snps[which(bcv.snps > 3)],main="Histogram of variance for SNPs with BCV > 3",xlab = "variance estimate",ylab = "# of SNPs")
length(which(var.snps[which(bcv.snps > 3)] < .2))
interesting.bcv.snps <- which(var.snps[which(bcv.snps > 3)] < .2)
```

* A total of 9,219 SNPs have BCV values greater than 3.

* There is an interesting set of 624 SNPs which have a BCV greater than 3 but variance less than 0.2


### Filter the nearzerovar

* The 'nearzerovar' function will check for things which have less than 10 or less unique values and 95/5 most common/least common (19:1 ratio).  This subset was interesting in the last

```{r check.vars}
# This near zero var will check for things which have less than 10 or less unique values and 95/5 most common/least common (19:1 ratio)
check.vars <- nearZeroVar(x = bio.012.df,allowParallel = T)

# How many did not meet these thresholds?
length(check.vars)
## 6,624 SNPs did not meet threshold
```

* A total of 6624 SNPs did not meet this threshold, let's take a look at their BCV values

```{r nearzero.stats}
hist(bcv.snps[check.vars])
hist(bcv.snps[-check.vars])
bcv.3.snps <- which(bcv.snps > 3)
```

* There is an odd set which have > 3 BCV. Let's subset those out too.

```{r nearzero.bcv}
near.zero.bcv3.snps <- bcv.3.snps[which(bcv.3.snps %in% check.vars)]
far.zero.bcv3.snps <- bcv.3.snps[-which(bcv.3.snps %in% check.vars)]
```

* Roughly 8966 SNPs had a bcv > 3 and were not removed by the nearzero filter

* A total of 253 SNPs were identified as being removed by the nearzerovar BUT they had BCV > 3. We will keep those for further inspection.

* How do the variance of these SNPs look?

```{r near.zero.var}
summary(var.snps[near.zero.bcv3.snps])
summary(var.snps[far.zero.bcv3.snps])
```

## Predictions

* Only output is displayed. The code for the predictions is available in the markdown file on github

* In all cases a LOO CV was done by removing a single family and training on the remaining families

### All transcripts: BIO Reps

* Bio-reps: All 140K SNPs x 189 biological replicates were converted into a correlation matrix and used with OmicKriging to predict volume breeding values in a LOOCV. Since almost all families contain more than 1 biological rep, the family mean is taken for each set of predictions.  Varying correlation weights were used to evaulate the impact of the weight on the prediction accuracy.

```{r alltxpts.bio,echo=FALSE}
cor.weights <- seq(.01,.99,.01)
cor.mat <- cor(t(bio.012.df))
rownames(cor.mat) <- 1:nrow(bio.phenos); colnames(cor.mat) <- 1:nrow(bio.phenos)
rownames(bio.phenos) <- 1:nrow(bio.phenos)

fam.cors <- unlist(mclapply(1:length(cor.weights),function(each.weight){
c.weight <- cor.weights[each.weight]
fam.predictions <- sapply(1:length(u.fams),function(each.fam){
TEST.fams <- which(bio.phenos$fam_id %in% u.fams[each.fam])
TRAIN.fams <- c(1:189)[-TEST.fams]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(c.weight),
                        pheno = bio.phenos,phenoname = "Volume")
mean(predictions[,2])
})

cor(fam.predictions,fam.phenos$Volume)
},mc.cores=34))

gg.data1 <- data.frame(cbind("cor"=fam.cors,"weight"=cor.weights))

#ggplot(data = gg.data,aes(x=cor,y=weight,colour=cor))+
#  geom_point() + labs(x="Predicted BV vs. True BV correlation (r)",y="Weight used on correlation matrix",colour #= "(r) value") + ggtitle(paste0("EW prediction vs. test correlations across weights using \n OmicKriging and #biological SNPs")) 
```

### All transcripts: FAMILY-level

* Fam reps: Instead of using the biological rep SNP matrix, this time the family mean SNP matrix is used. Since the data frame has 56 rows we do not have to take the mean of predictions here.

```{r alltxpts.fam,echo=FALSE}
cor.mat <- cor(t(fam.012.df))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)
cor.weights <- seq(.01,.99,.01)

fam.cors <- unlist(mclapply(1:length(cor.weights),function(each.weight){
c.weight <- cor.weights[each.weight]

fam.predictions <- sapply(1:length(u.fams),function(each.fam){
TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(c.weight),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})
cor(fam.predictions,fam.phenos$Volume)
},mc.cores=34))

gg.data2 <- data.frame(cbind("cor"=fam.cors,"weight"=cor.weights))

ggplot(data = gg.data,aes(x=cor,y=weight,colour=cor))+
  geom_point() + labs(x="Predicted BV vs. True BV correlation (r)",y="Weight used on correlation matrix",colour = "(r) value") + ggtitle(paste0("EW prediction vs. test correlations across weights using \n OmicKriging and family-mean SNPs")) 
```


### BCV transcripts: FAMILY-level

* Test only included Snps where the BCV > 3

```{r bcvtxpts.fam,echo=FALSE}
select.snps <- which(bcv.snps > 3)
cor.mat <- cor(t(fam.012.df[, select.snps]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

fam.cors <- unlist(mclapply(1:length(cor.weights),function(each.weight){
c.weight <- cor.weights[each.weight]

fam.predictions <- sapply(1:length(u.fams),function(each.fam){
TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(c.weight),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})
cor(fam.predictions,fam.phenos$Volume)
},mc.cores=34))

gg.data3 <- data.frame(cbind("cor"=fam.cors,"weight"=cor.weights))

ggplot(data = gg.data,aes(x=cor,y=weight,colour=cor))+
  geom_point() + labs(x="Predicted BV vs. True BV correlation (r)",y="Weight used on correlation matrix",colour = "(r) value") + ggtitle(paste0("EW prediction vs. test correlations across weights using \n OmicKriging and family-mean SNPs: BCV > 3")) 
```

* Test BCV > 3 and var < .2

```{r bcvtxpts.fam2,echo=FALSE}
select.snps <- which(bcv.snps > 3 & var.snps < .2)
cor.mat <- cor(t(fam.012.df[, select.snps]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

fam.cors <- unlist(mclapply(1:length(cor.weights),function(each.weight){
c.weight <- cor.weights[each.weight]

fam.predictions <- sapply(1:length(u.fams),function(each.fam){
TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(c.weight),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})
cor(fam.predictions,fam.phenos$Volume)
},mc.cores=34))

gg.data4 <- data.frame(cbind("cor"=fam.cors,"weight"=cor.weights))

ggplot(data = gg.data,aes(x=cor,y=weight,colour=cor))+
  geom_point() + labs(x="Predicted BV vs. True BV correlation (r)",y="Weight used on correlation matrix",colour = "(r) value") + ggtitle(paste0("EW prediction vs. test correlations across weights using \n OmicKriging and family-mean SNPs: BCV > 3 & var < .2")) 
```

* Test BCV > 3 and var > .2

```{r bcvtxpts.fam3, echo=FALSE}
select.snps <- which(bcv.snps > 3 & var.snps > .2)
cor.mat <- cor(t(fam.012.df[, select.snps]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

fam.cors <- unlist(mclapply(1:length(cor.weights),function(each.weight){
c.weight <- cor.weights[each.weight]

fam.predictions <- sapply(1:length(u.fams),function(each.fam){
TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(c.weight),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})
cor(fam.predictions,fam.phenos$Volume)
},mc.cores=34))

gg.data5 <- data.frame(cbind("cor"=fam.cors,"weight"=cor.weights))

ggplot(data = gg.data,aes(x=cor,y=weight,colour=cor))+
  geom_point() + labs(x="Predicted BV vs. True BV correlation (r)",y="Weight used on correlation matrix",colour = "(r) value") + ggtitle(paste0("EW prediction vs. test correlations across weights using \n OmicKriging and family-mean SNPs: BCV > 3 & var > .2")) 
```

* Test no near zero var and BCV > 3

```{r bcvtxpts.fam3, echo=FALSE}
select.snps <- far.zero.bcv3.snps
cor.mat <- cor(t(fam.012.df[, select.snps]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

fam.cors <- unlist(mclapply(1:length(cor.weights),function(each.weight){
c.weight <- cor.weights[each.weight]

fam.predictions <- sapply(1:length(u.fams),function(each.fam){
TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(c.weight),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})
cor(fam.predictions,fam.phenos$Volume)
},mc.cores=34))

gg.data6 <- data.frame(cbind("cor"=fam.cors,"weight"=cor.weights))

all.gg <- cbind(gg.data1[,1],gg.data2[,1],gg.data3[,1],gg.data4[,1],gg.data5[,1],gg.data6[,1])
all.gg.melt <- melt(data = all.gg,id="method")
all.gg.melt[,1] <- all.gg.melt[,1]/100
colnames(all.gg.melt) <- c("weight","method","cor")


ggplot(data = all.gg.melt,aes(x=cor,y=weight,colour=as.factor(method))) +
  geom_point() + labs(x="Predicted BV vs. True BV correlation (r)",y="Weight used on correlation matrix",color="Model") + ggtitle(paste0("EW prediction vs. test correlations across weights using \n OmicKriging across 6 different approaches")) 
```

### OK: Adjusted ANOVA

* Try subsetting on p-value with NO fdr adjustment: 0.05, 0.01, 0.001, 0.0001

```{r pred.pval}
p.val.subset <- .05
fam.predictions <- sapply(1:length(u.fams),function(each.fam){
  cor.mat <- cor(t(fam.012.df[,which((family_pvals[[each.fam]]) < p.val.subset)]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})

cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```

```{r pred.pval2}
p.val.subset <- .01
fam.predictions <- sapply(1:length(u.fams),function(each.fam){
  cor.mat <- cor(t(fam.012.df[,which((family_pvals[[each.fam]]) < p.val.subset)]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})

cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```

```{r pred.pval3}
p.val.subset <- .001
fam.predictions <- unlist(mclapply(1:length(u.fams),function(each.fam){
  cor.mat <- cor(t(fam.012.df[,which((family_pvals[[each.fam]]) < p.val.subset)]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
},mc.cores=30))

cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```

```{r pred.pval4}
p.val.subset <- .0001
fam.predictions <- unlist(mclapply(1:length(u.fams),function(each.fam){
  cor.mat <- cor(t(fam.012.df[,which((family_pvals[[each.fam]]) < p.val.subset)]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
},mc.cores=30))

cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```


#### Use pval adjust

* Generate the adjusted p-values

```{r adjust.pval}
family_anova_padjust <- lapply(family_anova_scores,function(each.anova) p.adjust(p = each.anova,method = "fdr"))
family_pval_padjust <- lapply(family_pvals,function(each.pval) p.adjust(p = each.pval,method = "fdr"))
```

* Try subsetting on p-value with fdr adjustment: from 0.005 to 0.1 by .001

```{r}
p.val.subset <- seq(to = .1,from = .01,by = .001); cor.weight = .99
cor.list <- c()
rmse.list <- c()

for(each in 1:length(p.val.subset)){
 fam.preds <- unlist(mclapply(1:56,function(each.fam){
cor.mat <- cor(t(fam.012.df[,which(family_pval_padjust[[each.fam]] <= p.val.subset[each])]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])},mc.cores=30))

cor.list <- c(cor.list,cor(fam.preds,fam.phenos$Volume))
rmse.list <- c(rmse.list,rmse(fam.preds,fam.phenos$Volume))
}

# Plot correlation as a function of p-value subset
plot(p.val.subset,cor.list)
plot(p.val.subset,rmse.list)
summary(cor.list)
plot(cor.list,rmse.list)
```

* Take a look at .05 which is around the top prediction.

```{r}
p.val.subset <- .05
cor.mat <- cor(t(fam.012.df[,which(pvals.adjust <= p.val.subset)]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TRAIN.fams <- lgep.fams
TEST.fams <- ew.fams

predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,corlist = list(cor.mat),H2vec = c(.99),pheno = fam.phenos,phenoname = "Volume")
#predictions[,2:3] <- predictions[,2:3] - mean(pheno.57$Volume[which(pheno.57$fam_id %in% lgep.fams)])
cor(predictions$Ypred,predictions$Ytest)
plot(predictions$Ypred,predictions$Ytest)
```

### GLMNET

####  Try on all data

```{r}
TEST.fams <- which(fam.phenos$fam_id %in% ew.fams)
TRAIN.fams <- which(fam.phenos$fam_id %in% lgep.fams)

alpha.set <- seq(0,1,.01)
gl.cors <- c()
for(each in 1:length(alpha.set)){
gl.mod <- glmnet(x = fam.012.df[-TEST.fams,],
                  y = fam.phenos$Volume[-TEST.fams],alpha = alpha.set[each],standardize = F) 
predictions <- predict.glmnet(gl.mod,newx = fam.012.df[TEST.fams,])
gl.cors <- c(gl.cors,cor(predictions[,ncol(predictions)],fam.phenos$Volume[TEST.fams]))
}
plot(alpha.set,gl.cors)
```


* Try GLMNET on all data and then pass it to OK
    - Although the code is not run, the output displays supporting evidence that glment(alpha=0) is equivalent to Omic Kriging.
    
```
test.fams <- which(fam.phenos$fam_id %in% ew.fams)
train.fams <- which(fam.phenos$fam_id %in% lgep.fams)

TRAIN.fams <- lgep.fams
TEST.fams <- ew.fams

alpha.set <- seq(0,1,.01); cor.weight=.99
gl.cors <- c()
for(each in 1:length(alpha.set)){
gl.mod <- glmnet(x = fam.012.df[-test.fams,],
                  y = fam.phenos$Volume[-test.fams],alpha = alpha.set[each],standardize = F) 

 out <- gl.mod$beta
 select <- which(out[,ncol(out)] > 0)

 cor.mat <- cor(t(fam.012.df[,select]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,corlist = list(cor.mat),H2vec = c(cor.weight),pheno = fam.phenos,phenoname = "Volume")
predictions[,2:3] <- predictions[,2:3] - mean(fam.phenos$Volume[which(fam.phenos$fam_id %in% lgep.fams)])
gl.cors <- c(gl.cors,cor(predictions$Ypred,predictions$Ytest))}

plot(alpha.set,gl.cors)
```

#### Use un-adjusted pvals

* Look at unadjusted pvals from .005 to .1 by .001.

```{r unadjusted.pva}
TEST.fams <- which(fam.phenos$fam_id %in% ew.fams)
TRAIN.fams <- which(fam.phenos$fam_id %in% lgep.fams)
p.val.subset <- seq(to = .1,from = .005,by = .001);

 # Try on unadjusted pvals
gl.cor <- c()
for(each in 1:length(p.val.subset)){
gl.mod <- glmnet(x = fam.012.df[-TEST.fams,which(pvals <= p.val.subset[each])],
                  y = fam.phenos$Volume[-TEST.fams],alpha = 1,standardize = F) 

predictions <- predict.glmnet(gl.mod,newx = fam.012.df[TEST.fams,which(pvals <= p.val.subset[each])])
gl.cor <- c(gl.cor,cor(predictions[,ncol(predictions)],fam.phenos$Volume[TEST.fams]))
}
plot(p.val.subset,gl.cor)
```

#### Try on adjusted pvals

* Do the same for the adjusted p-values with the expectation the we will also test 3 different alpha's: 1,0,.5

```{r adjusted.pva}
# ALPHA = 1 Try on adjusted pvals ####
gl.cor <- c()
for(each in 1:length(p.val.subset)){
gl.mod <- glmnet(x = fam.012.df[-TEST.fams,which(pvals.adjust <= p.val.subset[each])],
                  y = fam.phenos$Volume[-TEST.fams],alpha = 1,standardize = F) 

predictions <- predict.glmnet(gl.mod,newx = fam.012.df[TEST.fams,which(pvals.adjust <= p.val.subset[each])])
gl.cor <- c(gl.cor,cor(predictions[,ncol(predictions)],fam.phenos$Volume[TEST.fams]))
}
plot(p.val.subset,gl.cor)

# ALPHA = 0 ####
gl.cor <- c()
for(each in 1:length(p.val.subset)){
gl.mod <- glmnet(x = fam.012.df[-TEST.fams,which(pvals.adjust <= p.val.subset[each])],
                  y = fam.phenos$Volume[-TEST.fams],alpha = 0,standardize = F) 

predictions <- predict.glmnet(gl.mod,newx = fam.012.df[TEST.fams,which(pvals.adjust <= p.val.subset[each])])
gl.cor <- c(gl.cor,cor(predictions[,ncol(predictions)],fam.phenos$Volume[TEST.fams]))
}
plot(p.val.subset,gl.cor)

# ALPHA = 0.5 ####
gl.cor <- c()
for(each in 1:length(p.val.subset)){
gl.mod <- glmnet(x = fam.012.df[-TEST.fams,which(pvals.adjust <= p.val.subset[each])],
                  y = fam.phenos$Volume[-TEST.fams],alpha = .5,standardize = F) 

predictions <- predict.glmnet(gl.mod,newx = fam.012.df[TEST.fams,which(pvals.adjust <= p.val.subset[each])])
gl.cor <- c(gl.cor,cor(predictions[,ncol(predictions)],fam.phenos$Volume[TEST.fams]))
}
plot(p.val.subset,gl.cor)
```

## Save image

```{r save}
save.image(file="./LGEP_EW_pred.snps.RData",compress=T)
```