---
title: 'Prediction of EW Volume BVâ€™s using LGEP: SNPs 012'
author: "Adam Festa"
date: "6/10/2018"
output: 
  html_document: 
    number_sections: yes
    theme: flatly
    toc: yes
    toc_depth: 5
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages(library(reshape2)); suppressPackageStartupMessages(library(parallel)); 
suppressPackageStartupMessages(library(OmicKriging));suppressPackageStartupMessages(library(glmnet)); 
suppressPackageStartupMessages(library(caret));suppressPackageStartupMessages(library(caretEnsemble));
suppressPackageStartupMessages(library(Metrics))
setwd("/mnt/mnt/media/disk6/ARF/shared")
```

## Load data

* Load the --012 output produced during the SNP filtering.

* File loaded below has no missing snps, MAF > .05, and are of at least Q30.

* Additionally, we get the rownames to match the names that are present in the phenos object

```{r load.data}
# Load matrix, indv file, and snp position file (indv file rownames & snp_pos colnames)
out.012 <- read.table("./snps/012/Q30.snps.nomiss.maf05.012",header = F)
rownames(out.012) <- as.character(read.table("./snps/012/Q30.snps.nomiss.maf05.012.indv")[,1])
colnames(out.012) <- paste0(as.character(read.table("./snps/012/Q30.snps.nomiss.maf05.012.pos")[,1]),
                            "_",
                            read.table("./snps/012/Q30.snps.nomiss.maf05.012.pos")[,2])

# Remove any extra "_" characters in the sample names
rel.colnames <- gsub(rownames(out.012),pattern = "_",replacement = "")
# Identify those matching the EW samples and replace the following statement
rel.colnames.ew <- gsub(rel.colnames,pattern = ".ew.bio.rep.merge.bam",replacement = "")

# We need to add "1000" to these names in order to match the phenos, 
# so here just subset the ones which when the string is forced to be numeric, it has numbers
ew.bio.reps <- which(!is.na(as.numeric(rel.colnames.ew)))

# The remaining 192 samples are LGEP
lgep.bio.reps <- c(1:192)[-ew.bio.reps]
# Now add 1000 to the EW sample names
mc.ew <- as.numeric(rel.colnames.ew[ew.bio.reps]) + 1000


# Subset the lgep bio reps, replace the matching pattern, and remove the index character attached to the sample number
mc.lgep <- rel.colnames[lgep.bio.reps]
mc.lgep <- gsub(pattern = "*.lgep.bio.rep.merge.bam",replacement = "",x = mc.lgep)
mc.lgep <- substr(mc.lgep,1,nchar(mc.lgep)-1)

# Finally replace the original column names with the adjusted colnames and remove vars
rel.colnames[ew.bio.reps] <- as.character(mc.ew)
rel.colnames[lgep.bio.reps] <- mc.lgep
head(rel.colnames)
rownames(out.012) <- rel.colnames
rm(rel.colnames,rel.colnames.ew,ew.bio.reps,lgep.bio.reps,mc.ew,mc.lgep)

## Load phenotype data ####
#load("~/Documents/Grad_Projects/Breeding-Value-Prediction/disk6directory/resources/expt.dat.720.RData")
load("/repos/Breeding-Value-Prediction/disk6directory/resources/expt.dat.720.RData")
expt.dat.720$animal_id <- as.character(expt.dat.720$animal_id)
expt.dat.720$fam_id <- as.character(expt.dat.720$fam_id)
expt.dat.720$batch <- as.character(expt.dat.720$batch)

# Create bio phenos from individuals with no missing Volume and who have unique, fam*animal*batch*vol combo
bio.phenos <- unique(expt.dat.720[which(!is.na(expt.dat.720$Volume) ==T),c("fam_id","animal_id","batch","Volume")])
```

* The bio phenos animal id and 012 matrix have the same style names but are not in the same order. Match 012 genos to phenotype data

```{r match}
# Subset bio.phenos to only include individuals within the snp mat
keep.index <-  which(rownames(out.012) %in% bio.phenos$animal_id)
out.012.subset <- out.012[keep.index,]

bio.pheno.subset <- bio.phenos[which(bio.phenos$animal_id %in% rownames(out.012.subset)),]
identical(bio.pheno.subset$animal_id[match(rownames(out.012.subset),bio.pheno.subset$animal_id)],rownames(out.012.subset))

bio.pheno.subset <- bio.pheno.subset[match(rownames(out.012.subset),bio.pheno.subset$animal_id),]
rownames(bio.pheno.subset) <- bio.pheno.subset$animal_id
```


## Generate family-level data

* Generate family phenos

```{r fam.phenos}
fam.phenos <- unique(bio.pheno.subset[,c("fam_id","Volume")])
rownames(fam.phenos) <- fam.phenos$fam_id
u.fams <- unique(fam.phenos$fam_id)
```

* Generate family mean SNP matrix using the FULL bio 012 matrix

```{r fam.mean}
fam.012 <- mclapply(1:nrow(fam.phenos),function(each.fam){
  these.rows <- which(bio.pheno.subset$fam_id %in% u.fams[each.fam])
    if(length(these.rows) < 2) { unlist(out.012.subset[these.rows,])
      } else {
         apply(out.012.subset[these.rows,],2,mean)
    }
},mc.cores=32)
fam.012 <- do.call(rbind,fam.012)
```



## Summary stats

```{r summary.counts}
# Filter BCV ####
# This near zero var will check for things which have less than 10 or less unique values.
# Also it'll include a cutoff at 95/5 most common/least common (19:1 ratio)
check.vars <- nearZeroVar(x = out.012.subset)
# Let's subset those
out.012.subset.0var <- out.012.subset[,-check.vars]

# Estimate variance of this set and calculate bcv (sd/mean)
var.snps <- apply(out.012.subset.0var,2,var)
sd.snps <- apply(out.012.subset.0var,2,sd)
mean.snps <- apply(out.012.subset.0var,2,mean)
bcv.snps <- sd.snps/mean.snps

# histogram shows an interesting bump of some which have high bcv
hist(bcv.snps)
hist(var.snps[which(bcv.snps > 3)])
select.snps <- which(bcv.snps > 3 & var.snps < .2)
train.dat.bio <- out.012.subset.0var[,select.snps]
```

## Predictions

### All transcripts: BIO Reps

* Bio-reps: NO SCALING
```{r alltxpts.bio}
cor.mat <- cor(t(out.012.subset))
rownames(cor.mat) <- 1:nrow(bio.pheno.subset); colnames(cor.mat) <- 1:nrow(bio.pheno.subset)
rownames(bio.pheno.subset) <- 1:nrow(bio.pheno.subset)

fam.predictions <- sapply(1:length(u.fams),function(each.fam){
TEST.fams <- which(bio.pheno.subset$fam_id %in% u.fams[each.fam])
TRAIN.fams <- c(1:189)[-TEST.fams]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = bio.pheno.subset,phenoname = "Volume")
mean(predictions[,2])
})
cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```

### All transcripts: FAMILY-level

* Fam reps: NO SCALING/CENTERING

```{r alltxpts.fam}
cor.mat <- cor(t(fam.012))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

fam.predictions <- sapply(1:length(u.fams),function(each.fam){
TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})
cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```


### BCV transcripts: FAMILY-level

* BCV > 3 & VAR < .2

```{r bcvtxpts.fam}
fam.012.cormat <- fam.012[,-check.vars]
#select.snps <- which(bcv.snps > 2 & var.snps > .3)
select.snps <- which(bcv.snps > 3)
fam.012.cormat <- fam.012.cormat[, select.snps]

cor.mat <- cor(t(fam.012.cormat))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

fam.predictions <- sapply(1:length(u.fams),function(each.fam){
TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})
cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```

### Linear model regression

* LOO regression to determine p-values for each snp with the test family left out.

* LOO anova scores with caret to get values for each snp with test family left out.

```{r loo.pval}
# Using the biological replicates as the training set, we will subset a single family and then test anova scores across the remaining families.
family_anova_scores <- mclapply(1:56,function(each.fam){
 fam.rows <- which(bio.pheno.subset$fam_id %in% u.fams[each.fam])
 train.dat <- out.012.subset[-fam.rows,]
 train.p <- bio.pheno.subset$Volume[-fam.rows]
 apply(train.dat,2,function(each.snp) anovaScores(x = each.snp,y=train.p))
},mc.cores=32)
save(family_anova_scores,file="./LOO_fam_snp_anova.RData",compress=T)

family_pvals <- mclapply(1:56,function(each.fam){
 fam.rows <- which(bio.pheno.subset$fam_id %in% u.fams[each.fam])
 train.dat <- out.012.subset[-fam.rows,]
 train.p <- bio.pheno.subset$Volume[-fam.rows]
 apply(train.dat,2,function(each.snp) {
   if(var(each.snp) < .001 ) { a <- 1} else {
    a <- summary(lm(train.p ~ each.snp))[[4]][[8]]}
   a
})
 },mc.cores=32)
save(family_pvals,file="./LOO_fam_snp_pvals.RData",compress=T)
```

```{r load.pvals, include=FALSE}
load("./LOO_fam_snp_anova.RData")
load("./LOO_fam_snp_pvals.RData")
```


#### Use straight p-vals

* Try subsetting on p-value with NO fdr adjustment: 0.05, 0.01, 0.001, 0.0001

```{r pred.pval}
p.val.subset <- .05
fam.predictions <- sapply(1:length(u.fams),function(each.fam){
  cor.mat <- cor(t(fam.012[,which((family_pvals[[each.fam]]) < p.val.subset)]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})

cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```

```{r pred.pval2}
p.val.subset <- .01
fam.predictions <- sapply(1:length(u.fams),function(each.fam){
  cor.mat <- cor(t(fam.012[,which((family_pvals[[each.fam]]) < p.val.subset)]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
})

cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```

```{r pred.pval3}
p.val.subset <- .001
fam.predictions <- unlist(mclapply(1:length(u.fams),function(each.fam){
  cor.mat <- cor(t(fam.012[,which((family_pvals[[each.fam]]) < p.val.subset)]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
},mc.cores=30))

cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```

```{r pred.pval4}
p.val.subset <- .0001
fam.predictions <- unlist(mclapply(1:length(u.fams),function(each.fam){
  cor.mat <- cor(t(fam.012[,which((family_pvals[[each.fam]]) < p.val.subset)]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])
},mc.cores=30))

cor(fam.predictions,fam.phenos$Volume)
plot(fam.predictions,fam.phenos$Volume)
```


#### Use pval adjust

* Generate the adjusted p-values

```{r adjust.pval}
family_anova_padjust <- lapply(family_anova_scores,function(each.anova) p.adjust(p = each.anova,method = "fdr"))
family_pval_padjust <- lapply(family_pvals,function(each.pval) p.adjust(p = each.pval,method = "fdr"))
```

* Try subsetting on p-value with fdr adjustment: from 0.005 to 0.1 by .001

```{r}
p.val.subset <- seq(to = .1,from = .01,by = .001); cor.weight = .99
cor.list <- c()
rmse.list <- c()

for(each in 1:length(p.val.subset)){
 fam.preds <- unlist(mclapply(1:56,function(each.fam){
cor.mat <- cor(t(fam.012[,which(family_pval_padjust[[each.fam]] <= p.val.subset[each])]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TEST.fams <- u.fams[each.fam]
TRAIN.fams <- u.fams[-each.fam]
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,
                        corlist = list(cor.mat),H2vec = c(.99),
                        pheno = fam.phenos,phenoname = "Volume")
(predictions[,2])},mc.cores=30))

cor.list <- c(cor.list,cor(fam.preds,fam.phenos$Volume))
rmse.list <- c(rmse.list,rmse(fam.preds,fam.phenos$Volume))
}

# Plot correlation as a function of p-value subset
plot(p.val.subset,cor.list)
plot(p.val.subset,rmse.list)
summary(cor.list)
plot(cor.list,rmse.list)
```

* Take a look at .05 which is around the top prediction.

```{r}
p.val.subset <- .05
cor.mat <- cor(t(fam.012[,which(pvals.adjust <= p.val.subset)]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)

TRAIN.fams <- lgep.fams
TEST.fams <- ew.fams

predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,corlist = list(cor.mat),H2vec = c(.99),pheno = fam.phenos,phenoname = "Volume")
#predictions[,2:3] <- predictions[,2:3] - mean(pheno.57$Volume[which(pheno.57$fam_id %in% lgep.fams)])
cor(predictions$Ypred,predictions$Ytest)
plot(predictions$Ypred,predictions$Ytest)
```

### GLMNET

####  Try on all data

```{r}
TEST.fams <- which(fam.phenos$fam_id %in% ew.fams)
TRAIN.fams <- which(fam.phenos$fam_id %in% lgep.fams)

alpha.set <- seq(0,1,.01)
gl.cors <- c()
for(each in 1:length(alpha.set)){
gl.mod <- glmnet(x = fam.012[-TEST.fams,],
                  y = fam.phenos$Volume[-TEST.fams],alpha = alpha.set[each],standardize = F) 
predictions <- predict.glmnet(gl.mod,newx = fam.012[TEST.fams,])
gl.cors <- c(gl.cors,cor(predictions[,ncol(predictions)],fam.phenos$Volume[TEST.fams]))
}
plot(alpha.set,gl.cors)
```


* Try GLMNET on all data and then pass it to OK
    - Although the code is not run, the output displays supporting evidence that glment(alpha=0) is equivalent to Omic Kriging.
    
```
test.fams <- which(fam.phenos$fam_id %in% ew.fams)
train.fams <- which(fam.phenos$fam_id %in% lgep.fams)

TRAIN.fams <- lgep.fams
TEST.fams <- ew.fams

alpha.set <- seq(0,1,.01); cor.weight=.99
gl.cors <- c()
for(each in 1:length(alpha.set)){
gl.mod <- glmnet(x = fam.012[-test.fams,],
                  y = fam.phenos$Volume[-test.fams],alpha = alpha.set[each],standardize = F) 

 out <- gl.mod$beta
 select <- which(out[,ncol(out)] > 0)

 cor.mat <- cor(t(fam.012[,select]))
rownames(cor.mat) <- rownames(fam.phenos); colnames(cor.mat) <- rownames(fam.phenos)
predictions <- okriging(idtest = TEST.fams,idtrain = TRAIN.fams,corlist = list(cor.mat),H2vec = c(cor.weight),pheno = fam.phenos,phenoname = "Volume")
predictions[,2:3] <- predictions[,2:3] - mean(fam.phenos$Volume[which(fam.phenos$fam_id %in% lgep.fams)])
gl.cors <- c(gl.cors,cor(predictions$Ypred,predictions$Ytest))}

plot(alpha.set,gl.cors)
```

#### Use un-adjusted pvals

* Look at unadjusted pvals from .005 to .1 by .001.

```{r unadjusted.pva}
TEST.fams <- which(fam.phenos$fam_id %in% ew.fams)
TRAIN.fams <- which(fam.phenos$fam_id %in% lgep.fams)
p.val.subset <- seq(to = .1,from = .005,by = .001);

 # Try on unadjusted pvals
gl.cor <- c()
for(each in 1:length(p.val.subset)){
gl.mod <- glmnet(x = fam.012[-TEST.fams,which(pvals <= p.val.subset[each])],
                  y = fam.phenos$Volume[-TEST.fams],alpha = 1,standardize = F) 

predictions <- predict.glmnet(gl.mod,newx = fam.012[TEST.fams,which(pvals <= p.val.subset[each])])
gl.cor <- c(gl.cor,cor(predictions[,ncol(predictions)],fam.phenos$Volume[TEST.fams]))
}
plot(p.val.subset,gl.cor)
```

#### Try on adjusted pvals

* Do the same for the adjusted p-values with the expectation the we will also test 3 different alpha's: 1,0,.5

```{r adjusted.pva}
# ALPHA = 1 Try on adjusted pvals ####
gl.cor <- c()
for(each in 1:length(p.val.subset)){
gl.mod <- glmnet(x = fam.012[-TEST.fams,which(pvals.adjust <= p.val.subset[each])],
                  y = fam.phenos$Volume[-TEST.fams],alpha = 1,standardize = F) 

predictions <- predict.glmnet(gl.mod,newx = fam.012[TEST.fams,which(pvals.adjust <= p.val.subset[each])])
gl.cor <- c(gl.cor,cor(predictions[,ncol(predictions)],fam.phenos$Volume[TEST.fams]))
}
plot(p.val.subset,gl.cor)

# ALPHA = 0 ####
gl.cor <- c()
for(each in 1:length(p.val.subset)){
gl.mod <- glmnet(x = fam.012[-TEST.fams,which(pvals.adjust <= p.val.subset[each])],
                  y = fam.phenos$Volume[-TEST.fams],alpha = 0,standardize = F) 

predictions <- predict.glmnet(gl.mod,newx = fam.012[TEST.fams,which(pvals.adjust <= p.val.subset[each])])
gl.cor <- c(gl.cor,cor(predictions[,ncol(predictions)],fam.phenos$Volume[TEST.fams]))
}
plot(p.val.subset,gl.cor)

# ALPHA = 0.5 ####
gl.cor <- c()
for(each in 1:length(p.val.subset)){
gl.mod <- glmnet(x = fam.012[-TEST.fams,which(pvals.adjust <= p.val.subset[each])],
                  y = fam.phenos$Volume[-TEST.fams],alpha = .5,standardize = F) 

predictions <- predict.glmnet(gl.mod,newx = fam.012[TEST.fams,which(pvals.adjust <= p.val.subset[each])])
gl.cor <- c(gl.cor,cor(predictions[,ncol(predictions)],fam.phenos$Volume[TEST.fams]))
}
plot(p.val.subset,gl.cor)
```

## Save image

```{r save}
save.image(file="./LGEP_EW_pred.snps.RData",compress=T)
```