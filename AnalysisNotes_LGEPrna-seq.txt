# Analysis of first two lanes of RNA-seq data - 14 May 2015
# Download to /media/seagate/LGEP, unpack tar archives, rename directories to lane01 and lane 02

# Change group ownership of lane01 and lane02 directories to students group:
chgrp students lane01 lane02	

# Write-protect tar archives 
chmod 444 Project_20150504-GSL028B-Whetten-X[12]POOL.tar

# Run fastqc in loop on all files in lane01 directory:
cd lane01
for file in *.fastq.gz; do fastqc ${file}; done

# Pull out all lines with Total Sequences data from all _fastqc directories:
# Remove the lines from the html files using sed 
grep -r "Total Sequences" *_fastqc | sed '/report.html/d'
## Output:
Sample_102k_fastqc/fastqc_data.txt:Total Sequences	8220144	
Sample_105l_fastqc/fastqc_data.txt:Total Sequences	7942888	
Sample_109u_fastqc/fastqc_data.txt:Total Sequences	6712035	
Sample_10p_fastqc/fastqc_data.txt:Total Sequences	4041291	# NB - index 16 library has much lower titer
Sample_111s_fastqc/fastqc_data.txt:Total Sequences	7242237	
Sample_114r_fastqc/fastqc_data.txt:Total Sequences	8504084	
Sample_115w_fastqc/fastqc_data.txt:Total Sequences	8260834	
Sample_116x_fastqc/fastqc_data.txt:Total Sequences	8476833	
Sample_120i_fastqc/fastqc_data.txt:Total Sequences	7761997	
Sample_127h_fastqc/fastqc_data.txt:Total Sequences	8559557	
Sample_129e_fastqc/fastqc_data.txt:Total Sequences	7627322	
Sample_136c_fastqc/fastqc_data.txt:Total Sequences	7532045	
Sample_143o_fastqc/fastqc_data.txt:Total Sequences	6760539	
Sample_17a_fastqc/fastqc_data.txt:Total Sequences	8238605	
Sample_19g_fastqc/fastqc_data.txt:Total Sequences	9372423	
Sample_23n_fastqc/fastqc_data.txt:Total Sequences	7021994	
Sample_24t_fastqc/fastqc_data.txt:Total Sequences	7298847	
Sample_33j_fastqc/fastqc_data.txt:Total Sequences	8570198	
Sample_36m_fastqc/fastqc_data.txt:Total Sequences	7727714	
Sample_37d_fastqc/fastqc_data.txt:Total Sequences	8332310	
Sample_41v_fastqc/fastqc_data.txt:Total Sequences	8800520	
Sample_47q_fastqc/fastqc_data.txt:Total Sequences	7434210	
Sample_68f_fastqc/fastqc_data.txt:Total Sequences	7735911	
Sample_72b_fastqc/fastqc_data.txt:Total Sequences	8966666	


# Run scythe adapter trimmer on files in lane01 directory, using a 50-nt TruSeq adapter sequence with 6 Ns in the index position:
for id in 102 105 109 10 111 114 115 116 120 127 129 136 143 17 19 23 24 33 36 37 41 47 68 ; do /home/ross/software/scythe/scythe -a ../TruSeq6NF.fa  Sample_${id}?.fastq.gz -o ${id}trim.fq; done

prior: 0.300
# 102
Adapter Trimming Complete
contaminated: 595432, uncontaminated: 7624712, total: 8220144
contamination rate: 0.072436

prior: 0.300
#105
Adapter Trimming Complete
contaminated: 493276, uncontaminated: 7449612, total: 7942888
contamination rate: 0.062103

prior: 0.300
# 109
Adapter Trimming Complete
contaminated: 317594, uncontaminated: 6394441, total: 6712035
contamination rate: 0.047317

prior: 0.300
# 10
Adapter Trimming Complete
contaminated: 128236, uncontaminated: 3913055, total: 4041291
contamination rate: 0.031731

prior: 0.300
# 111 
Adapter Trimming Complete
contaminated: 348431, uncontaminated: 6893806, total: 7242237
contamination rate: 0.048111

prior: 0.300
# 114 
Adapter Trimming Complete
contaminated: 364809, uncontaminated: 8139275, total: 8504084
contamination rate: 0.042898

prior: 0.300
# 115
Adapter Trimming Complete
contaminated: 401233, uncontaminated: 7859601, total: 8260834
contamination rate: 0.048571

prior: 0.300
# 116
Adapter Trimming Complete
contaminated: 361094, uncontaminated: 8115739, total: 8476833
contamination rate: 0.042598

prior: 0.300
# 120
Adapter Trimming Complete
contaminated: 575101, uncontaminated: 7186896, total: 7761997
contamination rate: 0.074092

prior: 0.300
# 127
Adapter Trimming Complete
contaminated: 780713, uncontaminated: 7778844, total: 8559557
contamination rate: 0.091210

prior: 0.300
# 129
Adapter Trimming Complete
contaminated: 619680, uncontaminated: 7007642, total: 7627322
contamination rate: 0.081245

prior: 0.300
# 136
Adapter Trimming Complete
contaminated: 553662, uncontaminated: 6978383, total: 7532045
contamination rate: 0.073508

prior: 0.300
# 143
Adapter Trimming Complete
contaminated: 310315, uncontaminated: 6450224, total: 6760539
contamination rate: 0.045901

prior: 0.300
# 17
Adapter Trimming Complete
contaminated: 451414, uncontaminated: 7787191, total: 8238605
contamination rate: 0.054793

prior: 0.300
# 19
Adapter Trimming Complete
contaminated: 947044, uncontaminated: 8425379, total: 9372423
contamination rate: 0.101046

prior: 0.300
# 23
Adapter Trimming Complete
contaminated: 352518, uncontaminated: 6669476, total: 7021994
contamination rate: 0.050202

prior: 0.300
# 24
Adapter Trimming Complete
contaminated: 355513, uncontaminated: 6943334, total: 7298847
contamination rate: 0.048708

prior: 0.300
# 33
Adapter Trimming Complete
contaminated: 665036, uncontaminated: 7905162, total: 8570198
contamination rate: 0.077599

prior: 0.300
# 36
Adapter Trimming Complete
contaminated: 407917, uncontaminated: 7319797, total: 7727714
contamination rate: 0.052786

prior: 0.300
# 37 
Adapter Trimming Complete
contaminated: 713944, uncontaminated: 7618366, total: 8332310
contamination rate: 0.085684

prior: 0.300
# 41
Adapter Trimming Complete
contaminated: 444430, uncontaminated: 8356090, total: 8800520
contamination rate: 0.050500

prior: 0.300
# 47
Adapter Trimming Complete
contaminated: 397022, uncontaminated: 7037188, total: 7434210
contamination rate: 0.053405

prior: 0.300
# 68
Adapter Trimming Complete
contaminated: 598672, uncontaminated: 7137239, total: 7735911
contamination rate: 0.077389

# To do quality trimming, use sickle trimmer program in /home/ross/software/sickle directory: for help on
# the format of single-end read processing, execute
/home/ross/software/sickle/sickle se

# Read counts from fastqc results for lane02 directory, using 
grep -r "Total Sequences" *_fastqc | sed '/report.html/d'
## Output
Sample_106e_fastqc/fastqc_data.txt:Total Sequences	8585008	
Sample_117v_fastqc/fastqc_data.txt:Total Sequences	6945862	
Sample_119o_fastqc/fastqc_data.txt:Total Sequences	8424483	
Sample_123d_fastqc/fastqc_data.txt:Total Sequences	8581520	
Sample_125l_fastqc/fastqc_data.txt:Total Sequences	8454370	
Sample_133a_fastqc/fastqc_data.txt:Total Sequences	7788462	
Sample_135t_fastqc/fastqc_data.txt:Total Sequences	8743581	
Sample_13f_fastqc/fastqc_data.txt:Total Sequences	8668204	
Sample_140u_fastqc/fastqc_data.txt:Total Sequences	7417893	
Sample_16w_fastqc/fastqc_data.txt:Total Sequences	7379113	
Sample_29x_fastqc/fastqc_data.txt:Total Sequences	7672881	
Sample_2q_fastqc/fastqc_data.txt:Total Sequences	8333124	
Sample_34g_fastqc/fastqc_data.txt:Total Sequences	8865123	
Sample_3s_fastqc/fastqc_data.txt:Total Sequences	7172414	
Sample_43r_fastqc/fastqc_data.txt:Total Sequences	9183316	
Sample_4j_fastqc/fastqc_data.txt:Total Sequences	8322069	
Sample_60m_fastqc/fastqc_data.txt:Total Sequences	8580571	
Sample_61i_fastqc/fastqc_data.txt:Total Sequences	9562447	
Sample_64p_fastqc/fastqc_data.txt:Total Sequences	9258861	
Sample_65n_fastqc/fastqc_data.txt:Total Sequences	7693539	
Sample_67c_fastqc/fastqc_data.txt:Total Sequences	8223051	
Sample_6b_fastqc/fastqc_data.txt:Total Sequences	8269085	
Sample_75h_fastqc/fastqc_data.txt:Total Sequences	9169233	
Sample_79k_fastqc/fastqc_data.txt:Total Sequences	8294324	

# Found bbmap suite of programs with bbduk program that can left-clip first 10 bases, filter adapters, and then quality trim
# in one step, much more quickly than any combination of fastx_toolkit, seqtk, scythe, or sickle.
# see http://seqanswers.com/forums/archive/index.php/t-42776.html for introductory post

# Create filttrim_rep1 directory for output of clipped, filtered, trimmed read files, in /media/seagate/LGEP

mkdir filttrim_rep1

# Create files with sample number+index letter from listing of lane01 and lane02 directories; use sed
# to remove the "lane0x/Sample_" prefix and ".fastq.gz" suffix from each sample ID:
ls lane01/*.gz |  sed 's%lane01/Sample_%%' | sed 's/.fastq.gz//' > lane1.ids
ls lane02/*.gz |  sed 's%lane02/Sample_%%' | sed 's/.fastq.gz//' > lane2.ids

# Use those files of ids to execute bbduk pipeline to left-clip first ten bases, filter adapters, and quality-trim to Phred20 in a bash loop:
time while read id; do ~/software/bbmap/bbduk.sh -Xmx10g in=lane01/Sample_${id}.fastq.gz out=filttrim_rep1/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < lane1.ids
# Memory use was < 1 G for each file. The time per file was typically < 1 min; the time command returned
real	20m43.612s  # for entire loop of 24 files.
user	92m6.460s
sys	2m47.115s
# Fraction of reads left ranges from 94.5% to over 98%; file sizes from 313M to 682M in filttrim_rep1 directory. Repeat for lane2:
time while read id; do ~/software/bbmap/bbduk.sh -Xmx10g in=lane02/Sample_${id}.fastq.gz out=filttrim_rep1/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < lane2.ids

# Build Sailfish index of Pita.86ktxptome.fa file in /media/sg3/ptaeda directory, using k-mer of 25:
sailfish index -t Pita.86ktxptome.fa -o Pita.86xtxptome.sfidx -k 25 -p 20

# Test sailfish quant as loop to see how much RAM it requires for files of ~7 to 9 million reads,
# saving output in new directory countfiles:
mkdir countfiles
time while read id; do sailfish quant -i /media/sg3/ptaeda/Pita.86ktxptome.sfidx -l "T=SE:S=S" -r <(zcat filttrim_rep1/${id}.fq.gz) -o countfiles/${id}_rep1 -p 6 -a; done < lane1.ids

# Monitor resource usage with top: gzip uses < 50% of a CPU; sailfish uses <650% and < 1% of RAM. Should be
# OK to run three loops in parallel, one per rep, as long as nobody else is using system resources.

# Plan for next 14 lanes: rest of rep1 (lanes 3-6), all of rep2 (lanes 7-12), 4 lanes of rep3 (lanes 13-16).
# Unpack each tar archive into a lane-specific directory
# Run the bbduk.sh loop for all files in each directory - may be able to use process substitution to avoid
# creating separate lists of sample ids for each lane; e.g. for lane01, use
while read id; do ~/software/bbmap/bbduk.sh -Xmx2g in=lane01/Sample_${id}.fastq.gz out=filttrim_rep1/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done <(ls lane01/*.gz |  sed 's%lane01/Sample_%%' | sed 's/.fastq.gz//' )
#### *** NB *** change lane01 (3x) and filttrim_rep1 (1x) as needed for each lane and rep. ***

# With only ~ 1G of memory required per loop, all 14 can be run at the same time if t=1 option is used to limit
# to one thread per process. Test process substitution and time with one processor, saving to tmp directory:
mkdir tmp.out
time while read id; do ~/software/bbmap/bbduk.sh -Xmx2g in=lane01/Sample_${id}.fastq.gz out=tmp.out/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane01/*.gz |  sed 's%lane01/Sample_%%' | sed 's/.fastq.gz//' )

# Takes slightly longer per file using only 1 thread (79 sec rather than 64 for 102k), but advantage of doing 14 lanes
# in parallel should outweigh that slight slowdown relative to processing in series with 24 cores/job. Memory
# use with single thread is < 200M, so allocation can be reduced more if desired.
# real	27m34.782s total time used to process lane01 with 1 core.
# user	58m24.728s
# sys	1m24.604s

# Example commands for lanes 3 - 6 (rest of rep1; saved to filttrim_rep1 output directory):
while read id; do ~/software/bbmap/bbduk.sh -Xmx2g in=lane03/Sample_${id}.fastq.gz out=tmp.out/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane03/*.gz |  sed 's%lane03/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do ~/software/bbmap/bbduk.sh -Xmx2g in=lane04/Sample_${id}.fastq.gz out=tmp.out/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane04/*.gz |  sed 's%lane04/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do ~/software/bbmap/bbduk.sh -Xmx2g in=lane05/Sample_${id}.fastq.gz out=tmp.out/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane05/*.gz |  sed 's%lane05/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do ~/software/bbmap/bbduk.sh -Xmx2g in=lane06/Sample_${id}.fastq.gz out=tmp.out/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane06/*.gz |  sed 's%lane06/Sample_%%' | sed 's/.fastq.gz//' ) &

# After all lanes are filtered and trimmed, run sailfish against k-mer hash of Pita.86ktxptome.fa for each sample,
# using similar loop for each rep.
while read id; do sailfish quant -i /media/sg3/ptaeda/Pita.86k.sfidx -l "T=SE:S=S" -r <(zcat 115stk.fq.gz)  -o sf115stk

#### Sat May 23 2015
# List of new files on brcwebportal server, Sat May 23 2015:
[ ]	Project_20150511-GSL029-B-Whetten-Y5POOL.tar	2015-05-22 14:59 	8.1G	 
[ ]	Project_20150511-GSL029-B-Whetten-Y6POOL.tar	2015-05-22 15:00 	10G	 
[ ]	Project_20150511-GSL029-B-Whetten-Z1POOL.tar	2015-05-22 15:06 	10G	 
[ ]	Project_20150511-GSL029-B-Whetten-Z2POOL.tar	2015-05-22 15:02 	10G	 
[ ]	Project_20150511-GSL029-B-Whetten-Z3POOL.tar	2015-05-22 15:04 	9.2G	 
[ ]	Project_20150511-GSL029-B-Whetten-Z4POOL.tar	2015-05-22 15:04 	11G	 
[ ]	Project_20150511-GSL029A-Whetten-X3POOL.tar	2015-05-21 15:24 	21G	 
[ ]	Project_20150511-GSL029A-Whetten-X4POOL.tar	2015-05-21 15:25 	16G	 
[ ]	Project_20150511-GSL029A-Whetten-X5POOL.tar	2015-05-21 15:29 	16G	 
[ ]	Project_20150511-GSL029A-Whetten-X6POOL.tar	2015-05-21 15:29 	19G	 
[ ]	Project_20150511-GSL029A-Whetten-Y1POOL.tar	2015-05-21 15:31 	18G	 
[ ]	Project_20150511-GSL029A-Whetten-Y2POOL.tar	2015-05-21 15:33 	20G	 
[ ]	Project_20150511-GSL029A-Whetten-Y3POOL.tar	2015-05-21 15:33 	20G	 
[ ]	Project_20150511-GSL029A-Whetten-Y4POOL.tar	2015-05-21 15:33 	19G	 

# Run two loops in parallel to download and save files:
for id in Y5 Y6 Z1 Z2 Z3 Z4; do wget --user=whetten --password=eRaugB8z -O ${id}.tar https://brcwebportal.cos.ncsu.edu/gsl/Whetten/Project_20150511-GSL029-B-Whetten-${id}POOL.tar; done

for ID in X3 X4 X5 X6 Y1 Y2 Y3 Y4; do wget --user=whetten --password=eRaugB8z -O ${ID}.tar https://brcwebportal.cos.ncsu.edu/gsl/Whetten/Project_20150511-GSL029A-Whetten-${ID}POOL.tar; done

# It took about 5 hours to download all 14 files. Untar with a similar loop:
for file in X3 X4 X5 X6 Y1 Y2 Y3 Y4 Y5 Y6 Z1 Z2 Z3 Z4; do tar -xf ${file}.tar; done

# As each tar archive is unpacked, move the resulting directory to a more conveniently-named version:
mv Project_20150511-GSL029A-Whetten-X3POOL lane03
mv Project_20150511-GSL029A-Whetten-X4POOL lane04
mv Project_20150511-GSL029A-Whetten-X5POOL lane05
mv Project_20150511-GSL029A-Whetten-X6POOL lane06

# Run loop of bbduk commands on those four files to complete rep1; save output to filttrim_rep1 directory,
# using 
while read id; do ~/software/bbmap/bbduk.sh -Xmx2g in=lane03/Sample_${id}.fastq.gz out=filttrim_rep1/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane03/*.gz |  sed 's%lane03/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do ~/software/bbmap/bbduk.sh -Xmx2g in=lane04/Sample_${id}.fastq.gz out=filttrim_rep1/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane04/*.gz |  sed 's%lane04/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do ~/software/bbmap/bbduk.sh -Xmx2g in=lane05/Sample_${id}.fastq.gz out=filttrim_rep1/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane05/*.gz |  sed 's%lane05/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do ~/software/bbmap/bbduk.sh -Xmx2g in=lane06/Sample_${id}.fastq.gz out=filttrim_rep1/${id}.fq.gz ref=~/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane06/*.gz |  sed 's%lane06/Sample_%%' | sed 's/.fastq.gz//' ) &

# Make a list of files in pool1 to compare with contents of tmp.out folder:
ls lane01/Sample_*.gz | sed 's%lane01/Sample_%%' | sed 's/.fastq.gz//' > pool1.list
ls lane02/Sample_*.gz | sed 's%lane02/Sample_%%' | sed 's/.fastq.gz//' >> pool1.list
ls lane03/Sample_*.gz | sed 's%lane03/Sample_%%' | sed 's/.fastq.gz//' >> pool1.list
ls lane04/Sample_*.gz | sed 's%lane04/Sample_%%' | sed 's/.fastq.gz//' >> pool1.list
ls lane05/Sample_*.gz | sed 's%lane05/Sample_%%' | sed 's/.fastq.gz//' >> pool1.list
ls lane06/Sample_*.gz | sed 's%lane06/Sample_%%' | sed 's/.fastq.gz//' >> pool1.list
sort pool1.list > pool1.tmp
mv pool1.tmp pool1.list

ls lane01_2/Sample_*.gz | sed 's%lane01_2/Sample_%%' | sed 's/.fastq.gz//' > pool2.list
ls lane02_2/Sample_*.gz | sed 's%lane02_2/Sample_%%' | sed 's/.fastq.gz//' >> pool2.list
ls lane03_2/Sample_*.gz | sed 's%lane03_2/Sample_%%' | sed 's/.fastq.gz//' >> pool2.list
ls lane04_2/Sample_*.gz | sed 's%lane04_2/Sample_%%' | sed 's/.fastq.gz//' >> pool2.list
ls lane05_2/Sample_*.gz | sed 's%lane05_2/Sample_%%' | sed 's/.fastq.gz//' >> pool2.list
ls lane06_2/Sample_*.gz | sed 's%lane06_2/Sample_%%' | sed 's/.fastq.gz//' >> pool2.list
sort pool2.list > pool2.tmp
mv pool2.tmp pool2.list

# Check for differences between samples in pool1.list and pool2.list - no differences reported
diff pool1.list pool2.list

#Created directory for trimmed lanes of rep2 and rep 3
mkdir filttrim_rep2
mkdir filttrim_rep3

#moved unpacked tar files to more convienent naming scheme for rep2
mv Project_20150511-GSL029A-Whetten-Y1POOL lane01_2; 
mv Project_20150511-GSL029A-Whetten-Y2POOL lane02_2;
mv Project_20150511-GSL029A-Whetten-Y3POOL lane03_2;
mv Project_20150511-GSL029A-Whetten-Y4POOL lane04_2;
mv Project_20150511-GSL029-B-Whetten-Y5POOL lane05_2;
mv Project_20150511-GSL029-B-Whetten-Y6POOL lane06_2

#Run loop of bbduk commands on all files to complete rep2; save output to filttrim_rep2 directory,
# using t=1 as specification for 1GB memory
#### *** NB *** change lane0* (3x) and filttrim_rep* (1x) as needed for each lane and rep. ***
while read id; do /home/ross/software/bbmap/bbduk.sh -Xmx2g in=lane01_2/Sample_${id}.fastq.gz out=filttrim_rep2/${id}.fq.gz ref=/home/ross/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 t=1 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane01_2/*.gz |  sed 's%lane01_2/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do /home/ross/software/bbmap/bbduk.sh -Xmx2g in=lane02_2/Sample_${id}.fastq.gz out=filttrim_rep2/${id}.fq.gz ref=/home/ross/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 t=1 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane02_2/*.gz |  sed 's%lane02_2/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do /home/ross/software/bbmap/bbduk.sh -Xmx2g in=lane03_2/Sample_${id}.fastq.gz out=filttrim_rep2/${id}.fq.gz ref=/home/ross/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 t=1 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane03_2/*.gz |  sed 's%lane03_2/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do /home/ross/software/bbmap/bbduk.sh -Xmx2g in=lane04_2/Sample_${id}.fastq.gz out=filttrim_rep2/${id}.fq.gz ref=/home/ross/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane04_2/*.gz |  sed 's%lane04_2/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do /home/ross/software/bbmap/bbduk.sh -Xmx2g in=lane05_2/Sample_${id}.fastq.gz out=filttrim_rep2/${id}.fq.gz ref=/home/ross/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane05_2/*.gz |  sed 's%lane05_2/Sample_%%' | sed 's/.fastq.gz//' ) &

while read id; do /home/ross/software/bbmap/bbduk.sh -Xmx2g in=lane06_2/Sample_${id}.fastq.gz out=filttrim_rep2/${id}.fq.gz ref=/home/ross/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 t=1 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane06_2/*.gz |  sed 's%lane06_2/Sample_%%' | sed 's/.fastq.gz//' )

#move tar files to more convienient naming scheme for rep3 (only 4 lanes at this time)
mv Project_20150511-GSL029-B-Whetten-Z1POOL lane01_3;
mv Project_20150511-GSL029-B-Whetten-Z2POOL lane02_3;
mv Project_20150511-GSL029-B-Whetten-Z3POOL lane03_3;
mv Project_20150511-GSL029-B-Whetten-Z4POOL lane04_3;

#Run loop of bbduk commands on first 4 lanes to begin rep3; save output to filttrim_rep3 directory,
# using t=1 as specification for 1GB memory
#### *** NB *** change lane0* (3x) and filttrim_rep* (1x) as needed for each lane and rep. ***

while read id; do /home/ross/software/bbmap/bbduk.sh -Xmx2g in=lane01_3/Sample_${id}.fastq.gz out=filttrim_rep3/${id}.fq.gz ref=/home/ross/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 t=1 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane01_3/*.gz |  sed 's%lane01_3/Sample_%%' | sed 's/.fastq.gz//' )

while read id; do /home/ross/software/bbmap/bbduk.sh -Xmx2g in=lane02_3/Sample_${id}.fastq.gz out=filttrim_rep3/${id}.fq.gz ref=/home/ross/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 t=1 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane02_3/*.gz |  sed 's%lane02_3/Sample_%%' | sed 's/.fastq.gz//' )

while read id; do /home/ross/software/bbmap/bbduk.sh -Xmx2g in=lane03_3/Sample_${id}.fastq.gz out=filttrim_rep3/${id}.fq.gz ref=/home/ross/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 t=1 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane03_3/*.gz |  sed 's%lane03_3/Sample_%%' | sed 's/.fastq.gz//' )

while read id; do /home/ross/software/bbmap/bbduk.sh -Xmx2g in=lane04_3/Sample_${id}.fastq.gz out=filttrim_rep3/${id}.fq.gz ref=/home/ross/software/bbmap/resources/truseq.fa.gz forcetrimleft=10 t=1 ktrim=r k=25 mink=12 hdist=1 qtrim=rl trimq=20 minlength=50; done < <(ls lane04_3/*.gz |  sed 's%lane04_3/Sample_%%' | sed 's/.fastq.gz//' )


# Lane01 samples from rep1 have already been analyzed with Sailfish - edit those sample ids out of pool1.list
# file so it contains only IDS from lanes 2 to 6, and run Sailfish on those.
comm -13 lane1.ids pool1.list >lanes2-6.ids
time while read id; do sailfish quant -i /media/sg3/ptaeda/Pita.86ktxptome.sfidx -l "T=SE:S=S" -r <(zcat filttrim_rep1/${id}.fq.gz) -o countfiles/${id}_rep1 -p 6 -a; done < lanes2-6.ids

# Run Sailfish on pool2:
while read id; do sailfish quant -i /media/sg3/ptaeda/Pita.86ktxptome.sfidx -l "T=SE:S=S" -r <(zcat filttrim_rep2/${id}.fq.gz) -o countfiles/${id}_rep2 -p 6 -a; done < pool2.list

# Create list of sample names from rep3 files:
ls lane01_3/Sample_*.gz | sed 's%lane01_3/Sample_%%' | sed 's/.fastq.gz//' > pool3.list
ls lane02_3/Sample_*.gz | sed 's%lane02_3/Sample_%%' | sed 's/.fastq.gz//' >> pool3.list
ls lane03_3/Sample_*.gz | sed 's%lane03_3/Sample_%%' | sed 's/.fastq.gz//' >> pool3.list
ls lane04_3/Sample_*.gz | sed 's%lane04_3/Sample_%%' | sed 's/.fastq.gz//' >> pool3.list

# In a different terminal window, set LD_LIBRARY_PATH variable and run Sailfish on rep3 samples:
export LD_LIBRARY_PATH=/home/ross/software/sailfish/lib
while read id; do sailfish quant -i /media/sg3/ptaeda/Pita.86ktxptome.sfidx -l "T=SE:S=S" -r <(zcat filttrim_rep3/${id}.fq.gz) -o countfiles/${id}_rep3 -p 6 -a; done < pool3.list


# To assemble a command line for pasting contig IDs (column1) and EstimatedNumReads (column7) from each of 384
# Sailfish output files into a single file, start with pool*.list files of sample IDs and add <(cut -f1,7 
# to beginning of line followed by space before sample ID, and _rep*/quant_bias_corrected.df ) \ after sample ID,
# with no space between \ and end of line. The double \\ at the end of the line prevents the \ from being
# understood as an escape character hiding the # sign - without the \\, the command gives a sed error about
# "unterminated 's' command". The # sign is used as a delimiter for the s command so the / in the replacement string
# is not confused with a / used as a delimiter. 
sed 's#^#<(tail -n +6 #' pool1.list | sed 's#$#_rep1/quant_bias_corrected.sf | cut -f1,7) \\#' > pool1.paste
sed 's#^#<(tail -n +6 #' pool2.list | sed 's#$#_rep2/quant_bias_corrected.sf | cut -f1,7) \\#' > pool2.paste
sed 's#^#<(tail -n +6 #' pool3.list | sed 's#$#_rep3/quant_bias_corrected.sf | cut -f1,7) \\#' > pool3.paste
cat pool1.paste pool2.paste pool3.paste > pool.all

#  use text editor to add 'paste' to beginning of first line and > 384samples.result to end of last.
### Execute the command from within the countfiles directory, so the individual sample 
### directories are visible to the cut commands. The columns will be unlabeled, but in the order in which
### the sample files are incorporated into the paste command, so merging the three pool*.list files will
### provide a list of column headings for use in R.

cat <(sed -e 's/$/_rep1/' ../pool1.list) <(sed -e 's/$/_rep2/' ../pool2.list) <(sed -e 's/$/_rep3/' ../pool3.list) > sample.names
# Odd-numbered columns are the list of contig IDS for each sample (column 1 cut from each output file) -
# should be 768 columns in 384samples.result output file. Confirm with awk:
head 384samples.result | awk '{print NF}'
# yes, first 10 lines all have 768 columns of data
# compare those using bash loop to make sure all samples listed contigs in same order in output files.
# Capture column 1 to a file to use for comparison, loop through all other columns with process substitution:
cut -f1 384samples.result > contigs.list
for I in {3..767..2}; do diff <(cut -f${I} 384samples.result) contigs.list; done
# The 'I in {3..767..2}' means 'the sequence beginning with 3 and ending with 767, increasing by 2'
# Nothing is returned, meaning no differences were detected between column 1 and any other column
# Use awk to print column 1 followed by all even-numbered columns to new file for analysis with DESeq2:
awk '{printf ("%s\t", $1); for(i=2;i<NF;i+=2) printf ("%d\t", $i); printf("%s\n",$NF)}' 384samples.result > 384samples.data

# Load the 384samples.data file into R with contig IDs as rownames, add sample.names as names of data columns.
# See Analysis_384samplesDESeq2.R for details.
# Use awk to see how many rows (genes) have some level of gene expression 
awk '{for(i=2;i<=NF;i++) sum+=$i}; {if(sum==0){count0++} else sum=0}END{print count0}' 384samples.data
# returns 9820 - 11.4% of 86008 transcripts have no detected reads at all.

# Both DESeq2 and edgeR can include batch or lane effects in models - it might be useful to include
# other effects as well, such as % germination or average germination time for each family, but lane effects
# are likely to be significant. Use a bash command to produce a file of rep # and lane # for each sample;
# use different lane numbers for different reps because there is no connection between lane01 of rep1 and lane01
# of rep2.
for I in {1..6}; do echo $(ls lane0${I}/*.fastq.gz | sed -e "s%lane0${I}/Sample_%%" | sed -e 's/.fastq.gz//') | awk -v N=$I '{for(i=1;i<=NF;i++)printf("%s",$i"\trep1\tlane"N"\n")}'; done > rep1_laneIDs.list

# rep2:
for I in {1..6}; do J=$(( I + 6 )); echo $(ls lane0${I}_2/*.fastq.gz | sed -e "s%lane0${I}_2/Sample_%%" | sed -e 's/.fastq.gz//') | awk -v N=$J '{for(i=1;i<=NF;i++)printf("%s",$i"\trep2\tlane"N"\n")}'; done > rep2_laneIDs.list

# rep3
for I in {1..4}; do J=$(( I + 12 )); echo $(ls lane0${I}_3/*.fastq.gz | sed -e "s%lane0${I}_3/Sample_%%" | sed -e 's/.fastq.gz//') | awk -v N=$J '{for(i=1;i<=NF;i++)printf("%s",$i"\trep3\tlane"N"\n")}'; done > rep3_laneIDs.list

# combine files into one:
cat rep1_laneIDs.list rep2_laneIDs.list rep3_laneIDs.list > allreps_laneIDs.list

# Limma package allows generalized linear models with variables that account for library and lane effects
# Create a new file, expt.dat, that contains sample IDs (1 - 144 with index letters), rep, lane, and parent of interest
# in columns name, sample, rep, lane, and ID. "Sample" accounts for variation among libraries, "lane" among lanes - 
# the rep variation is a combination of these two, and is not needed as a separate factor. "ID" is the variable
# of interest for differential expression. 46 unique IDs in that column, plus "ID" header and NOOOO for sample 144.
# "name" is sample_rep, eg 100n_rep1 - same as column header using sample.names file.

# See Analysis_limma-voom.R for details

## 1 June 2015 - counting lines in each sample and saving results by lane, to estimate covariance among reps
## due to lane effects. Adam's exptdata file contains fields of name, sample, rep, lane, and ID - use that as input:
while read -a line; do zcat filttrim_${line[2]}/${line[1]}.fq.gz | wc -l >> ${line[3]}.filesize; done < <(tail -n +2 analysis/exptdata)
